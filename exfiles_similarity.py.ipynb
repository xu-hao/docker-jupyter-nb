{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import livy, pprint, requests\n",
    "host = \"http://35.182.207.50:18601\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................"
     ]
    }
   ],
   "source": [
    "session_url = livy.openSession(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_url = session_url + \"/upload-file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(upload_file_url, files={\"file\": open(\"gtex_rnaseq_prep_profiles_short.tsv\",\"rb\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '''\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "path = SparkFiles.get(\"gtex_rnaseq_prep_profiles_short.tsv\")\n",
    "\n",
    "dataheaderindex = 2\n",
    "\n",
    "with open(path) as inp:\n",
    "    headers = inp.readline().strip().split(\"\\t\")\n",
    "    # ids = []\n",
    "    # features = []\n",
    "    data = []\n",
    "    for line in inp:\n",
    "        row = line.strip().split('\\t')\n",
    "        if len(row) < dataheaderindex:\n",
    "            continue\n",
    "        # id = row[:dataheaderindex]\n",
    "        feature = map(float, row[dataheaderindex:])\n",
    "        data.append(feature)\n",
    "    data2 = list(map(lambda x : [Vectors.dense(*x)], zip(*data)))\n",
    "\n",
    "df = spark.createDataFrame(data2, [\"features\"])\n",
    "\n",
    "r1 = Correlation.corr(df, \"features\").head()\n",
    "print(\"Pearson correlation matrix:\\\\n\" + str(r1))\n",
    "\n",
    "r2 = Correlation.corr(df, \"features\", \"spearman\").head()\n",
    "print(\"Spearman correlation matrix:\\\\n\" + str(r2))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........."
     ]
    }
   ],
   "source": [
    "r = livy.execStatement(host, session_url, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progress': 1.0, 'state': 'available', 'output': {'execution_count': 0, 'status': 'ok', 'data': {'text/plain': 'Pearson correlation matrix:\\nRow(pearson(features)=DenseMatrix(9, 9, [1.0, 0.2447, 0.2068, 0.4914, 0.3069, -0.0747, 0.1278, 0.3957, ..., 0.0188, 0.2582, 0.5914, 0.3462, 0.1979, 0.0447, 0.3077, 1.0], False))\\nSpearman correlation matrix:\\nRow(spearman(features)=DenseMatrix(9, 9, [1.0, 0.223, 0.3006, 0.4801, 0.3286, 0.3539, 0.37, 0.5528, ..., 0.1393, 0.2525, 0.4988, 0.3717, 0.4857, 0.1324, 0.3615, 1.0], False))'}}, 'code': '\\nfrom pyspark import SparkContext\\nfrom pyspark import SparkFiles\\nfrom pyspark.ml.linalg import Vectors\\nfrom pyspark.ml.stat import Correlation\\n\\npath = SparkFiles.get(\"gtex_rnaseq_prep_profiles_short.tsv\")\\n\\ndataheaderindex = 2\\n\\nwith open(path) as inp:\\n    headers = inp.readline().strip().split(\"\\t\")\\n    # ids = []\\n    # features = []\\n    data = []\\n    for line in inp:\\n        row = line.strip().split(\\'\\t\\')\\n        if len(row) < dataheaderindex:\\n            continue\\n        # id = row[:dataheaderindex]\\n        feature = map(float, row[dataheaderindex:])\\n        data.append(feature)\\n    data2 = list(map(lambda x : [Vectors.dense(*x)], zip(*data)))\\n\\ndf = spark.createDataFrame(data2, [\"features\"])\\n\\nr1 = Correlation.corr(df, \"features\").head()\\nprint(\"Pearson correlation matrix:\\\\n\" + str(r1))\\n\\nr2 = Correlation.corr(df, \"features\", \"spearman\").head()\\nprint(\"Spearman correlation matrix:\\\\n\" + str(r2))\\n', 'id': 0}\n"
     ]
    }
   ],
   "source": [
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text/plain': 'Pearson correlation matrix:\\n'\n",
      "               'Row(pearson(features)=DenseMatrix(9, 9, [1.0, 0.2447, 0.2068, '\n",
      "               '0.4914, 0.3069, -0.0747, 0.1278, 0.3957, ..., 0.0188, 0.2582, '\n",
      "               '0.5914, 0.3462, 0.1979, 0.0447, 0.3077, 1.0], False))\\n'\n",
      "               'Spearman correlation matrix:\\n'\n",
      "               'Row(spearman(features)=DenseMatrix(9, 9, [1.0, 0.223, 0.3006, '\n",
      "               '0.4801, 0.3286, 0.3539, 0.37, 0.5528, ..., 0.1393, 0.2525, '\n",
      "               '0.4988, 0.3717, 0.4857, 0.1324, 0.3615, 1.0], False))'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(r.json()[\"output\"][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "livy.closeSession(session_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
